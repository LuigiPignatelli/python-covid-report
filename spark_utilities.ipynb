{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "283f3258-53c5-43f5-ad52-4192a3719c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dfb4f5-673b-43f2-a1ac-45a455f9b7e9",
   "metadata": {},
   "source": [
    "# *Spark utilities*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd191b9b-b1eb-4dc7-ab09-cad6f43ce8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.functions import cast, concat, concat_ws, count, contains, lit, col, lpad, min, max\n",
    "from pyspark.sql.types import DecimalType, StringType, DoubleType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0dbcc5e-5c28-4c50-a10a-5b1848e1f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43730018-5cba-463b-a963-041018ab0082",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = configparser.ConfigParser()\n",
    "parser.read(\"pipeline.config\")\n",
    "\n",
    "host = parser.get(\"sql_server\", \"hostname\")\n",
    "port = parser.get(\"sql_server\", \"port\")\n",
    "db_name = parser.get(\"sql_server\", \"database\")\n",
    "usr = parser.get(\"sql_server\", \"username\")\n",
    "pwd = parser.get(\"sql_server\", \"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122f6cf3-9e86-408f-ac74-76fb375d0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"jdbc:sqlserver://{0}:{1};databaseName={2};user={3};password={4};encrypt=true;trustServerCertificate=true\"\n",
    "jdbcURI = uri.format(host, port, db_name, usr, pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615c0578-a797-4135-a738-d2bfe3511b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(jdbcURI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459aed57-97a7-4cd8-855b-1b1861c02481",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = \"com.microsoft.sqlserver.jdbc.SQLServerDriver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a2e8c6-08f9-4442-8184-5571e624e29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "following variables have been created:\n",
      "db_name\n",
      "jdbcURI\n",
      "driver\n"
     ]
    }
   ],
   "source": [
    "print(\"following variables have been created:\\ndb_name\\njdbcURI\\ndriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f305ac18-1fd8-40a9-8b7f-03fab67f3c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "jre11 = \"driver/enu/jars/mssql-jdbc-12.6.1.jre11.jar\"\n",
    "# jre8 = \"driver/enu/jars/mssql-jdbc-12.6.1.jre8.jar\"\n",
    "# jars = ','.join([jre8, jre11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a8e153f-d743-4bc8-94de-1edb844ece67",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Practice\")\n",
    "    # .config(\"spark.jars\", jre11)\n",
    "    # .config(\"spark.driver.extraClassPath\", \"C:\\SQLDrivers\\sqljdbc_12.6\\enu\\mssql-jdbc-12.6.1.jre11.jar\")\n",
    "    .config(\"spark.driver.extraClassPath\", jre11)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ce3a46-d22a-4b9b-98d6-910f33f45b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2697975a850>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565522b3-6892-4486-8f76-d2eb355772e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# *Spark Catalog*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fdaec7f-3e0a-4484-b291-c54fac853826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6b086b6-ea22-45ec-ad04-c9564f28586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.catalog.listTables()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
